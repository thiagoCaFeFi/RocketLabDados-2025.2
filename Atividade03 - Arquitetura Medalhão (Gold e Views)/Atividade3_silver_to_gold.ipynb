{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "09d6566c-cdb9-4980-96fc-6ed782e397fb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.window import Window\n",
    "from pyspark.sql.types import IntegerType, DecimalType, DateType\n",
    "\n",
    "# Configuração do Ambiente\n",
    "catalogo = \"medalhao\"\n",
    "silver = \"silver\"\n",
    "gold = \"gold\"\n",
    "\n",
    "# Define o catálogo e cria o schema Gold\n",
    "spark.sql(f\"USE CATALOG {catalogo}\")\n",
    "spark.sql(f\"CREATE SCHEMA IF NOT EXISTS {gold}\")\n",
    "spark.sql(f\"USE SCHEMA {gold}\")\n",
    "\n",
    "print(f\"Ambiente configurado: Catálogo '{catalogo}', Schema '{gold}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "10d58cb2-1e54-43d6-ad26-57c435a549b2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Criação da Tabela Fato: gold.ft_vendas_consumidor_local\n",
    "# Relacionando vendas com a localização do consumidor para otimização logística.\n",
    "\n",
    "df_pedidos_total = spark.table(f\"{catalogo}.{silver}.ft_pedidos_total\")\n",
    "df_consumidores = spark.table(f\"{catalogo}.{silver}.ft_consumidores\")\n",
    "\n",
    "df_gold1 = (\n",
    "    df_pedidos_total.alias(\"p\")\n",
    "    .join(df_consumidores.alias(\"c\"), \"id_consumidor\")\n",
    "    .select(\n",
    "        F.col(\"p.id_pedido\"),\n",
    "        F.col(\"p.id_consumidor\"),\n",
    "        F.col(\"p.valor_total_pago_brl\").alias(\"valor_total_pedido_brl\"),\n",
    "        F.col(\"p.valor_total_pago_usd\"),\n",
    "        F.col(\"c.cidade\"),\n",
    "        F.col(\"c.estado\"),\n",
    "        F.col(\"p.data_pedido\")\n",
    "    )\n",
    ")\n",
    "\n",
    "tabela_gold1 = f\"{catalogo}.{gold}.ft_vendas_consumidor_local\"\n",
    "df_gold1.write.format(\"delta\").mode(\"overwrite\").option(\"overwriteSchema\", \"true\").saveAsTable(tabela_gold1)\n",
    "print(f\"Tabela criada: {tabela_gold1}\")\n",
    "df_gold1.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "960a6c64-bdf4-451c-ab65-9015bf98826b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Criação da View Analítica: gold.view_total_compras_por_consumidor\n",
    "spark.sql(f\"\"\"\n",
    "    CREATE OR REPLACE VIEW {catalogo}.{gold}.view_total_compras_por_consumidor AS\n",
    "    SELECT \n",
    "        cidade,\n",
    "        estado,\n",
    "        COUNT(*) AS quantidade_vendas,\n",
    "        SUM(valor_total_pedido_brl) AS valor_total_localidade\n",
    "    FROM {catalogo}.{gold}.ft_vendas_consumidor_local\n",
    "    GROUP BY cidade, estado\n",
    "\"\"\")\n",
    "print(\"View criada: view_total_compras_por_consumidor\")\n",
    "\n",
    "# Consulta de Negócio\n",
    "print(\">> Executando consulta: Total de vendas por estado\")\n",
    "spark.sql(f\"\"\"\n",
    "    SELECT estado, SUM(valor_total_localidade) AS total_vendas_brl\n",
    "    FROM {catalogo}.{gold}.view_total_compras_por_consumidor\n",
    "    GROUP BY estado\n",
    "    ORDER BY total_vendas_brl DESC\n",
    "\"\"\").display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "aedb3109-45fa-4357-ad75-55cbff3a2206",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Criação da Tabela Fato: gold.ft_atrasos_pedidos_local_vendedor\n",
    "# Identificando gargalos logísticos por região e vendedor.\n",
    "\n",
    "df_pedidos = spark.table(f\"{catalogo}.{silver}.ft_pedidos\")\n",
    "df_itens = spark.table(f\"{catalogo}.{silver}.ft_itens_pedidos\")\n",
    "df_consumidores = spark.table(f\"{catalogo}.{silver}.ft_consumidores\")\n",
    "\n",
    "df_gold2 = (\n",
    "    df_pedidos.alias(\"p\")\n",
    "    .join(df_consumidores.alias(\"c\"), \"id_consumidor\")\n",
    "    # Join com itens é necessário para trazer o vendedor\n",
    "    .join(df_itens.alias(\"i\"), \"id_pedido\") \n",
    "    .select(\n",
    "        F.col(\"p.id_pedido\"),\n",
    "        F.col(\"i.id_vendedor\"),\n",
    "        F.col(\"p.id_consumidor\"),\n",
    "        F.col(\"p.entrega_no_prazo\"),\n",
    "        F.col(\"p.tempo_entrega_dias\"),\n",
    "        F.col(\"p.tempo_entrega_estimado_dias\"),\n",
    "        F.col(\"c.cidade\"),\n",
    "        F.col(\"c.estado\")\n",
    "    )\n",
    ")\n",
    "\n",
    "tabela_gold2 = f\"{catalogo}.{gold}.ft_atrasos_pedidos_local_vendedor\"\n",
    "df_gold2.write.format(\"delta\").mode(\"overwrite\").option(\"overwriteSchema\", \"true\").saveAsTable(tabela_gold2)\n",
    "print(f\"Tabela criada: {tabela_gold2}\")\n",
    "df_gold2.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d27d4ce0-d550-41ed-9810-395372bdfce9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# View: Tempo Médio de Entrega por Localidade\n",
    "spark.sql(f\"\"\"\n",
    "    CREATE OR REPLACE VIEW {catalogo}.{gold}.view_tempo_medio_entrega_localidade AS\n",
    "    SELECT \n",
    "        cidade,\n",
    "        estado,\n",
    "        AVG(tempo_entrega_dias) AS tempo_medio_entrega,\n",
    "        AVG(tempo_entrega_estimado_dias) AS tempo_medio_estimado,\n",
    "        CASE \n",
    "            WHEN AVG(tempo_entrega_dias) > AVG(tempo_entrega_estimado_dias) THEN 'SIM' \n",
    "            ELSE 'NÃO'\n",
    "        END AS entrega_maior_que_estimado\n",
    "    FROM {catalogo}.{gold}.ft_atrasos_pedidos_local_vendedor\n",
    "    GROUP BY cidade, estado\n",
    "\"\"\")\n",
    "print(\"View criada: view_tempo_medio_entrega_localidade\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "14d3d8c3-9f95-446d-a0db-32f7f649da01",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# View: Pontualidade do Vendedor\n",
    "spark.sql(f\"\"\"\n",
    "    CREATE OR REPLACE VIEW {catalogo}.{gold}.view_vendedor_pontualidade AS\n",
    "    SELECT \n",
    "        id_vendedor,\n",
    "        COUNT(*) AS total_pedidos,\n",
    "        SUM(CASE WHEN entrega_no_prazo = 'Não' THEN 1 ELSE 0 END) AS total_atrasados,\n",
    "        (SUM(CASE WHEN entrega_no_prazo = 'Não' THEN 1 ELSE 0 END) / COUNT(*)) * 100 AS percentual_atraso\n",
    "    FROM {catalogo}.{gold}.ft_atrasos_pedidos_local_vendedor\n",
    "    GROUP BY id_vendedor\n",
    "\"\"\")\n",
    "print(\"View criada: view_vendedor_pontualidade\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ce07736c-da92-4cfa-aa67-ab8199ef0351",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Criação da Dimensão Tempo: gold.dm_tempo\n",
    "# Facilitando análises temporais (drill-down) permitindo visualização do macro para o micro\n",
    "\n",
    "df_tempo = (\n",
    "    spark.range(1)\n",
    "    .select(F.explode(F.sequence(\n",
    "        F.to_date(F.lit(\"2016-01-01\")),\n",
    "        F.to_date(F.lit(\"2018-12-31\")),\n",
    "        F.expr(\"INTERVAL 1 DAY\")\n",
    "    )).alias(\"sk_tempo\"))\n",
    "    .withColumn(\"ano\", F.year(\"sk_tempo\"))\n",
    "    .withColumn(\"trimestre\", F.quarter(\"sk_tempo\"))\n",
    "    .withColumn(\"mes\", F.month(\"sk_tempo\"))\n",
    "    .withColumn(\"mes_nome\", F.date_format(\"sk_tempo\", \"MMMM\")) # Nome do mês\n",
    "    .withColumn(\"semana_do_ano\", F.weekofyear(\"sk_tempo\"))\n",
    "    .withColumn(\"dia\", F.dayofmonth(\"sk_tempo\"))\n",
    "    .withColumn(\"dia_da_semana_num\", F.dayofweek(\"sk_tempo\"))\n",
    "    .withColumn(\"dia_da_semana_nome\", F.date_format(\"sk_tempo\", \"EEEE\")) # Nome do dia\n",
    "    .withColumn(\n",
    "        \"eh_fim_de_semana\", \n",
    "        F.when(F.dayofweek(\"sk_tempo\").isin(1, 7), \"Sim\").otherwise(\"Não\") # 1=Dom, 7=Sab no Spark padrão\n",
    "    )\n",
    ")\n",
    "\n",
    "tabela_tempo = f\"{catalogo}.{gold}.dm_tempo\"\n",
    "df_tempo.write.format(\"delta\").mode(\"overwrite\").option(\"overwriteSchema\", \"true\").saveAsTable(tabela_tempo)\n",
    "print(f\"Tabela criada: {tabela_tempo}\")\n",
    "df_tempo.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "55320b15-a0e5-48fa-9ba8-08a8d7e466a5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Criação da Fato Geral: gold.ft_vendas_geral\n",
    "# Tabela central para BI, granularidade no nível do Item.\n",
    "\n",
    "df_itens = spark.table(f\"{catalogo}.{silver}.ft_itens_pedidos\")\n",
    "df_pedidos = spark.table(f\"{catalogo}.{silver}.ft_pedidos\")\n",
    "df_produtos = spark.table(f\"{catalogo}.{silver}.ft_produtos\")\n",
    "df_vendedores = spark.table(f\"{catalogo}.{silver}.ft_vendedores\")\n",
    "df_consumidores = spark.table(f\"{catalogo}.{silver}.ft_consumidores\")\n",
    "df_dolar = spark.table(f\"{catalogo}.{silver}.dm_cotacao_dolar\")\n",
    "df_avaliacoes = spark.table(f\"{catalogo}.silver.ft_avaliacoes_pedidos\") # Necessário para avaliação média\n",
    "# Definição da Janela para preencher cotação faltante (fins de semana)\n",
    "window_ffill = Window.orderBy(\"p.pedido_compra_timestamp\").rowsBetween(Window.unboundedPreceding, 0)\n",
    "\n",
    "df_gold3 = (\n",
    "    df_itens.alias(\"i\")\n",
    "    # Joins usando strings fundem as colunas chave\n",
    "    .join(df_pedidos.alias(\"p\"), \"id_pedido\")\n",
    "    .join(df_produtos.alias(\"pr\"), \"id_produto\")\n",
    "    .join(df_vendedores.alias(\"v\"), \"id_vendedor\")\n",
    "    .join(df_consumidores.alias(\"c\"), \"id_consumidor\")\n",
    "    # Join explícito (data) mantém os aliases\n",
    "    .join(df_dolar.alias(\"d\"), F.to_date(F.col(\"p.pedido_compra_timestamp\")) == F.col(\"d.data\"), \"left\")\n",
    "    .join(df_avaliacoes.alias(\"a\"), \"id_pedido\", \"left\")\n",
    "    # Correção do Dólar pra finais de semana\n",
    "    .withColumn(\"cotacao_final\", F.last(\"d.cotacao_dolar\", ignorenulls=True).over(window_ffill))\n",
    "    .select(\n",
    "        F.col(\"id_pedido\"),\n",
    "        F.col(\"i.id_item\"),\n",
    "        F.col(\"id_consumidor\").alias(\"fk_cliente\"),\n",
    "        F.col(\"id_produto\").alias(\"fk_produto\"),\n",
    "        F.col(\"id_vendedor\").alias(\"fk_vendedor\"),\n",
    "        F.to_date(F.col(\"p.pedido_compra_timestamp\")).alias(\"fk_tempo\"),\n",
    "        F.col(\"p.status\").alias(\"status_pedido\"),\n",
    "        F.col(\"p.tempo_entrega_dias\"),\n",
    "        F.col(\"p.entrega_no_prazo\"),\n",
    "        F.col(\"i.preco_brl\").alias(\"valor_produto_brl\"),\n",
    "        F.col(\"i.preco_frete\").alias(\"valor_frete_brl\"),\n",
    "        (F.col(\"i.preco_brl\") + F.col(\"i.preco_frete\")).alias(\"valor_total_item_brl\"),\n",
    "        (F.col(\"i.preco_brl\") / F.col(\"cotacao_final\")).cast(\"decimal(12,2)\").alias(\"valor_produto_usd\"),\n",
    "        (F.col(\"i.preco_frete\") / F.col(\"cotacao_final\")).cast(\"decimal(12,2)\").alias(\"valor_frete_usd\"),\n",
    "        ((F.col(\"i.preco_brl\") + F.col(\"i.preco_frete\")) / F.col(\"cotacao_final\")).cast(\"decimal(12,2)\").alias(\"valor_total_item_usd\"),\n",
    "        F.col(\"cotacao_final\").alias(\"cotacao_dolar\"),\n",
    "        F.col(\"a.avaliacao\").alias(\"avaliacao_pedido\")\n",
    "    )\n",
    ")\n",
    "\n",
    "tabela_gold3 = f\"{catalogo}.{gold}.ft_vendas_geral\"\n",
    "df_gold3.write.format(\"delta\").mode(\"overwrite\").option(\"overwriteSchema\", \"true\").saveAsTable(tabela_gold3)\n",
    "print(f\"Tabela criada com sucesso: {tabela_gold3}\")\n",
    "\n",
    "df_gold3.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "41a4079c-5ee4-450f-a1ea-48e68479526d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# View: gold.view_vendas_por_periodo\n",
    "spark.sql(f\"\"\"\n",
    "    CREATE OR REPLACE VIEW {catalogo}.{gold}.view_vendas_por_periodo AS\n",
    "    SELECT \n",
    "        t.ano,\n",
    "        t.trimestre,\n",
    "        t.mes,\n",
    "        t.mes_nome,\n",
    "        t.dia,\n",
    "        t.dia_da_semana_num,\n",
    "        t.dia_da_semana_nome,\n",
    "        COUNT(DISTINCT f.id_pedido) AS total_pedidos,\n",
    "        COUNT(f.id_item) AS total_itens,\n",
    "        SUM(f.valor_total_item_brl) AS receita_total_brl,\n",
    "        SUM(f.valor_total_item_usd) AS receita_total_usd,\n",
    "        AVG(f.valor_total_item_brl) AS ticket_medio_brl,\n",
    "        AVG(f.avaliacao_pedido) AS avaliacao_media\n",
    "    FROM {catalogo}.{gold}.ft_vendas_geral f\n",
    "    JOIN {catalogo}.{gold}.dm_tempo t ON f.fk_tempo = t.sk_tempo\n",
    "    GROUP BY t.ano, t.trimestre, t.mes, t.mes_nome, t.dia, t.dia_da_semana_num, t.dia_da_semana_nome\n",
    "\"\"\")\n",
    "print(\"View criada: view_vendas_por_periodo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "104e5e5f-797f-47ad-b471-cd89cb033281",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Consultas Analíticas\n",
    "print(\">> Executando consultas analíticas de BI...\")\n",
    "\n",
    "print(\"1. Dia da semana com maior receita total (BRL):\")\n",
    "spark.sql(f\"\"\"\n",
    "    SELECT dia_da_semana_nome, SUM(receita_total_brl) as receita_total \n",
    "    FROM {catalogo}.{gold}.view_vendas_por_periodo \n",
    "    GROUP BY dia_da_semana_nome \n",
    "    ORDER BY receita_total DESC LIMIT 1\n",
    "\"\"\").display()\n",
    "\n",
    "print(\"2. Mês com maior ticket médio (BRL) no último ano:\")\n",
    "spark.sql(f\"\"\"\n",
    "    SELECT mes_nome, ticket_medio_brl \n",
    "    FROM {catalogo}.{gold}.view_vendas_por_periodo \n",
    "    WHERE ano = (SELECT MAX(ano) FROM {catalogo}.{gold}.view_vendas_por_periodo) \n",
    "    ORDER BY ticket_medio_brl DESC LIMIT 1\n",
    "\"\"\").display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "68a4cd63-8649-4115-89a4-d5d8cd5b7509",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# View: Top Produto\n",
    "spark.sql(f\"\"\"\n",
    "    CREATE OR REPLACE VIEW {catalogo}.{gold}.view_top_produto AS\n",
    "    SELECT\n",
    "        f.fk_produto AS id_produto,\n",
    "        p.categoria_produto,\n",
    "        COUNT(*) AS quantidade_vendida,\n",
    "        COUNT(DISTINCT f.id_pedido) AS total_pedidos,\n",
    "        SUM(f.valor_total_item_brl) AS receita_brl,\n",
    "        SUM(f.valor_total_item_usd) AS receita_usd,\n",
    "        AVG(f.valor_produto_brl) AS preco_medio_brl,\n",
    "        AVG(f.avaliacao_pedido) AS avaliacao_media,\n",
    "        AVG(p.peso_produto_gramas) AS peso_medio_gramas\n",
    "    FROM {catalogo}.{gold}.ft_vendas_geral f\n",
    "    JOIN {catalogo}.{silver}.ft_produtos p ON f.fk_produto = p.id_produto\n",
    "    GROUP BY f.fk_produto, p.categoria_produto\n",
    "\"\"\")\n",
    "print(\"View criada: view_top_produto\")\n",
    "# Check dos tipos\n",
    "view_top_produto = spark.sql(f\"SELECT * FROM {catalogo}.{gold}.view_top_produto\")\n",
    "display(view_top_produto)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ee33eab0-f241-4249-82ac-6a01ecf33509",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# View: Vendas Produtos Estéticos (CTE)\n",
    "spark.sql(f\"\"\"\n",
    "    CREATE OR REPLACE VIEW {catalogo}.{gold}.view_vendas_produtos_esteticos AS\n",
    "    WITH base AS (\n",
    "        SELECT \n",
    "            f.id_pedido,\n",
    "            f.id_item,\n",
    "            f.fk_produto,\n",
    "            f.valor_total_item_brl,\n",
    "            f.valor_total_item_usd,\n",
    "            f.avaliacao_pedido,\n",
    "            t.ano,\n",
    "            t.mes\n",
    "        FROM {catalogo}.{gold}.ft_vendas_geral f\n",
    "        JOIN {catalogo}.{gold}.dm_tempo t\n",
    "            ON f.fk_tempo = t.sk_tempo\n",
    "        JOIN {catalogo}.{silver}.ft_produtos p\n",
    "            ON f.fk_produto = p.id_produto\n",
    "        WHERE p.categoria_produto LIKE 'fashion%'\n",
    "    )\n",
    "    SELECT \n",
    "        ano,\n",
    "        mes,\n",
    "        'Fashion' as categoria_produto,\n",
    "        COUNT(DISTINCT id_pedido) AS total_pedidos,\n",
    "        COUNT(*) AS total_itens_vendidos,\n",
    "        SUM(valor_total_item_brl) AS receita_total_brl,\n",
    "        SUM(valor_total_item_usd) AS receita_total_usd,\n",
    "        AVG(valor_total_item_brl) AS ticket_medio_brl,\n",
    "        AVG(valor_total_item_usd) AS ticket_medio_usd,\n",
    "        AVG(avaliacao_pedido) AS avaliacao_media\n",
    "    FROM base\n",
    "    GROUP BY ano, mes\n",
    "\"\"\")\n",
    "print(\"View criada: view_vendas_produtos_esteticos\")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": {
    "hardware": {
     "accelerator": null,
     "gpuPoolId": null,
     "memory": null
    }
   },
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Atividade3_silver_to_gold",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
